{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/3ry2l6hs6qz2yjr9tcj8bq6c0000gp/T/ipykernel_73578/264455222.py:11: DtypeWarning: Columns (58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  3.  4.  2.  1.  5.]\n",
      "count    11017.000000\n",
      "mean         2.744849\n",
      "std          0.623447\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          3.000000\n",
      "max          5.000000\n",
      "Name: acuity_code, dtype: float64\n",
      "[-1.  3.  4.  2.  1.  5.]\n",
      "\n",
      "Removing target column 'spell_episode_los' before saving...\n",
      "Processing complete! Output shape: (41846, 18)\n",
      "\n",
      "Processed columns: ['chronic_condition_obesity_flag', 'chronic_condition_respiratory_flag', 'frailty_score', 'attendancetype', 'arrival_mode_description', 'place_of_incident', 'source_of_ref_description', 'acuity_code', 'inj_or_ail', 'NEWS2', 'ae_unplanned_attendance', 'location', 'Deprivation Decile', 'season_of_the_admission', 'presenting_complaint_encoded', 'presenting_complaint_count', 'presenting_complaint_is_rare', 'NEWS2_missing']\n",
      "\n",
      "Data types:\n",
      "chronic_condition_obesity_flag          Int64\n",
      "chronic_condition_respiratory_flag      Int64\n",
      "frailty_score                         float64\n",
      "attendancetype                          int64\n",
      "arrival_mode_description                int64\n",
      "place_of_incident                       int64\n",
      "source_of_ref_description               int64\n",
      "acuity_code                           float64\n",
      "inj_or_ail                              int64\n",
      "NEWS2                                   int64\n",
      "ae_unplanned_attendance                 int64\n",
      "location                                int64\n",
      "Deprivation Decile                      Int64\n",
      "season_of_the_admission               float64\n",
      "presenting_complaint_encoded          float64\n",
      "presenting_complaint_count            float64\n",
      "presenting_complaint_is_rare            int64\n",
      "NEWS2_missing                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders import CatBoostEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "input_path = Path(\"data/raw/wwlLancMsc_data.csv\")\n",
    "output_path = Path(\"data/processed/merge_Sophie_col_80_100.csv\")\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "last_20_cols = df.columns[-20:].tolist()\n",
    "df_my = df[last_20_cols].copy()\n",
    "\n",
    "target_col = \"spell_episode_los\" \n",
    "if target_col in df.columns:\n",
    "    df_my[target_col] = df[target_col]\n",
    "    target = df_my[target_col]\n",
    "else:\n",
    "    target = None\n",
    "\n",
    "# PROCESSING \n",
    "\n",
    "# 1. chronic_condition_obesity_flag\n",
    "if \"chronic_condition_obesity_flag\" in df_my.columns:\n",
    "    df_my[\"chronic_condition_obesity_flag\"] = df_my[\"chronic_condition_obesity_flag\"].replace([\"NA\"], np.nan)\n",
    "    df_my[\"chronic_condition_obesity_flag\"] = df_my[\"chronic_condition_obesity_flag\"].astype(\"Int64\")\n",
    "\n",
    "# 2. chronic_condition_respiratory_flag\n",
    "if \"chronic_condition_respiratory_flag\" in df_my.columns:\n",
    "    df_my[\"chronic_condition_respiratory_flag\"] = df_my[\"chronic_condition_respiratory_flag\"].replace([\"NA\"], np.nan)\n",
    "    df_my[\"chronic_condition_respiratory_flag\"] = df_my[\"chronic_condition_respiratory_flag\"].astype(\"Int64\")\n",
    "\n",
    "# 3. frailty_score\n",
    "if \"frailty_score\" in df_my.columns:\n",
    "    df_my[\"frailty_score\"] = (\n",
    "        df_my[\"frailty_score\"]\n",
    "        .astype(str)\n",
    "        .str.extract(r\"(\\d+)\")[0]\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# 4. Arrival_Date - will be deleted after arrival_date_time processing\n",
    "# 5. arrival_date_time\n",
    "if \"arrival_date_time\" in df_my.columns and \"Arrival_Date\" in df_my.columns:#\n",
    "    \n",
    "    # Parse Arrival_Date\n",
    "    df_my[\"Arrival_Date\"] = pd.to_datetime(df_my[\"Arrival_Date\"], errors=\"coerce\")\n",
    "    \n",
    "    # Read raw arrival_date_time from original file\n",
    "    raw = pd.read_csv(\n",
    "        input_path,\n",
    "        usecols=[\"arrival_date_time\"],\n",
    "        dtype=str\n",
    "    ).loc[df_my.index, \"arrival_date_time\"].astype(str).str.strip()\n",
    "    \n",
    "    # Parse with both date formats\n",
    "    adt_dayfirst = pd.to_datetime(raw, dayfirst=True, errors=\"coerce\")\n",
    "    adt_monthfirst = pd.to_datetime(raw, dayfirst=False, errors=\"coerce\")\n",
    "    \n",
    "    # Initialize final series\n",
    "    final = pd.Series(pd.NaT, index=df_my.index, dtype='datetime64[ns]')\n",
    "    \n",
    "    # Match day-first format with Arrival_Date\n",
    "    mask_match_day = (\n",
    "        df_my[\"Arrival_Date\"].notna() & adt_dayfirst.notna() &\n",
    "        (adt_dayfirst.dt.date == df_my[\"Arrival_Date\"].dt.date)\n",
    "    )\n",
    "    final[mask_match_day] = adt_dayfirst[mask_match_day]\n",
    "    \n",
    "    # Match month-first format with Arrival_Date\n",
    "    mask_match_month = (\n",
    "        df_my[\"Arrival_Date\"].notna() & adt_monthfirst.notna() &\n",
    "        final.isna() &\n",
    "        (adt_monthfirst.dt.date == df_my[\"Arrival_Date\"].dt.date)\n",
    "    )\n",
    "    final[mask_match_month] = adt_monthfirst[mask_match_month]\n",
    "    \n",
    "    # Fill remaining with best guess\n",
    "    remaining = final.isna()\n",
    "    final[remaining] = adt_dayfirst[remaining].combine_first(adt_monthfirst[remaining])\n",
    "    \n",
    "    df_my[\"arrival_date_time\"] = final\n",
    "    \n",
    "    # Check for mismatches\n",
    "    mismatch_df = df_my[\n",
    "        df_my[\"Arrival_Date\"].notna() &\n",
    "        df_my[\"arrival_date_time\"].notna() &\n",
    "        (df_my[\"Arrival_Date\"].dt.date != df_my[\"arrival_date_time\"].dt.date)\n",
    "    ]\n",
    "    \n",
    "    def month_to_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 1 #\"Winter\"\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 2 # \"Spring\"\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 3 # \"Summer\"\n",
    "        elif month in [9, 10, 11]:\n",
    "            return 4 # \"Autumn\"\n",
    "        return None\n",
    "\n",
    "    df_my[\"season_of_the_admission\"] = (\n",
    "        df_my[\"arrival_date_time\"]\n",
    "        .dt.month\n",
    "        .apply(month_to_season)\n",
    "    )\n",
    "    df_my[\"season_of_the_admission\"] = df_my[\"season_of_the_admission\"].replace([\"NA\"], np.nan)\n",
    "    df_my[\"season_of_the_admission\"] = df_my[\"season_of_the_admission\"].replace([np.nan], -1)\n",
    "\n",
    "    df_my = df_my.drop(columns=[\"Arrival_Date\", \"arrival_date_time\"])\n",
    "\n",
    "\n",
    "# 6. attendancetype\n",
    "if \"attendancetype\" in df_my.columns:\n",
    "    df_my[\"attendancetype\"] = df_my[\"attendancetype\"].fillna(\"Unknown\")\n",
    "    le_attendance = LabelEncoder()\n",
    "    df_my[\"attendancetype\"] = le_attendance.fit_transform(df_my[\"attendancetype\"])\n",
    "\n",
    "# 7. initial_assessment_date_time - Delete\n",
    "if \"initial_assessment_date_time\" in df_my.columns:\n",
    "    df_my = df_my.drop(columns=[\"initial_assessment_date_time\"])\n",
    "\n",
    "# 8. sex_description.y - Delete\n",
    "if \"sex_description.y\" in df_my.columns:\n",
    "    df_my = df_my.drop(columns=[\"sex_description.y\"])\n",
    "\n",
    "# 9. arrival_mode_description\n",
    "if \"arrival_mode_description\" in df_my.columns:\n",
    "    df_my[\"arrival_mode_description\"] = df_my[\"arrival_mode_description\"].replace([\"NA\", 0], np.nan)\n",
    "    df_my[\"arrival_mode_description\"] = df_my[\"arrival_mode_description\"].fillna(\"Unknown\")\n",
    "    le_arrival_mode = LabelEncoder()\n",
    "    df_my[\"arrival_mode_description\"] = le_arrival_mode.fit_transform(df_my[\"arrival_mode_description\"])\n",
    "\n",
    "# 10. place_of_incident\n",
    "if \"place_of_incident\" in df_my.columns:\n",
    "    df_my[\"place_of_incident\"] = df_my[\"place_of_incident\"].fillna(\"Unknown\")\n",
    "    le_place = LabelEncoder()\n",
    "    df_my[\"place_of_incident\"] = le_place.fit_transform(df_my[\"place_of_incident\"])\n",
    "\n",
    "# 11. source_of_ref_description\n",
    "if \"source_of_ref_description\" in df_my.columns:\n",
    "    df_my[\"source_of_ref_description\"] = df_my[\"source_of_ref_description\"].fillna(\"Unknown\")\n",
    "    le_source = LabelEncoder()\n",
    "    df_my[\"source_of_ref_description\"] = le_source.fit_transform(df_my[\"source_of_ref_description\"])\n",
    "\n",
    "# 12. presenting_complaint - CatBoost encoding\n",
    "if \"presenting_complaint\" in df_my.columns:\n",
    "    df_my[\"presenting_complaint\"] = df_my[\"presenting_complaint\"].fillna(\"Unknown\")\n",
    "    \n",
    "    if target is not None:\n",
    "        # Out-of-fold CatBoost encoding\n",
    "        k_folds = KFold(n_splits=5, shuffle=True, random_state=98)\n",
    "        oof_values = pd.Series(index=df_my.index, dtype=float)\n",
    "        \n",
    "        for tr_index, val_index in k_folds.split(df_my):\n",
    "            encoder = CatBoostEncoder(cols=[\"presenting_complaint\"], a=20.0)\n",
    "            encoder.fit(\n",
    "                df_my.iloc[tr_index][[\"presenting_complaint\"]], \n",
    "                target.iloc[tr_index]\n",
    "            )\n",
    "            oof_values.iloc[val_index] = encoder.transform(\n",
    "                df_my.iloc[val_index][[\"presenting_complaint\"]]\n",
    "            )[\"presenting_complaint\"]\n",
    "        \n",
    "        df_my[\"presenting_complaint_encoded\"] = oof_values\n",
    "        \n",
    "        # Add frequency count\n",
    "        freq = df_my[\"presenting_complaint\"].map(df[\"presenting_complaint\"].value_counts())\n",
    "        df_my[\"presenting_complaint_count\"] = freq\n",
    "        df_my[\"presenting_complaint_count\"] = df_my[\"presenting_complaint_count\"].replace([\"NA\"], np.nan)\n",
    "        df_my[\"presenting_complaint_count\"] = df_my[\"presenting_complaint_count\"].replace([np.nan], -1)\n",
    "        \n",
    "        # Add rare flag (categories with less than 10 occurrences)\n",
    "        df_my[\"presenting_complaint_is_rare\"] = (freq < 10).astype(int)\n",
    "        \n",
    "        # Drop original column after encoding\n",
    "        df_my = df_my.drop(columns=[\"presenting_complaint\"])\n",
    "    else:\n",
    "        print(\"  Skipping CatBoost encoding (no target variable)\")\n",
    "        # Keep as categorical for CatBoost - no encoding needed\n",
    "\n",
    "# 13. acuity_code\n",
    "if \"acuity_code\" in df_my.columns:\n",
    "    print(df_my[\"acuity_code\"].unique())\n",
    "    print(df_my[\"acuity_code\"].describe())\n",
    "    df_my[\"acuity_code\"] = df_my[\"acuity_code\"].replace([\"NA\"], np.nan)\n",
    "    df_my[\"acuity_code\"] = df_my[\"acuity_code\"].replace([np.nan], -1)\n",
    "    print(df_my[\"acuity_code\"].unique())\n",
    "    df_my[\"acuity_code\"] = pd.to_numeric(df_my[\"acuity_code\"], errors=\"coerce\")\n",
    "\n",
    "# 14. inj_or_ail - Delete\n",
    "if \"inj_or_ail\" in df_my.columns:\n",
    "    df_my[\"inj_or_ail\"] = df_my[\"inj_or_ail\"].fillna(\"Unknown\")\n",
    "    le_source = LabelEncoder()\n",
    "    df_my[\"inj_or_ail\"] = le_source.fit_transform(df_my[\"inj_or_ail\"])\n",
    "\n",
    "# 15. attend_dis_description - Delete\n",
    "if \"attend_dis_description\" in df_my.columns:\n",
    "    df_my = df_my.drop(columns=[\"attend_dis_description\"])\n",
    "\n",
    "# 16. ae_unplanned_attendance\n",
    "if \"ae_unplanned_attendance\" in df_my.columns:\n",
    "    df_my[\"ae_unplanned_attendance\"] = df_my[\"ae_unplanned_attendance\"].fillna(0).astype(int)\n",
    "\n",
    "# 17. location - CatBoost encoding\n",
    "if \"location\" in df_my.columns:\n",
    "    df_my[\"location\"] = df_my[\"location\"].fillna(\"Unknown\")\n",
    "    le_source = LabelEncoder()\n",
    "    df_my[\"location\"] = le_source.fit_transform(df_my[\"location\"])\n",
    "\n",
    "# 18. ID - delete\n",
    "    df_my = df_my.drop(columns=[\"ID\"])\n",
    "\n",
    "# 19. Deprivation Decile\n",
    "if \"Deprivation Decile\" in df_my.columns:\n",
    "    df_my[\"Deprivation Decile\"] = pd.to_numeric(df_my[\"Deprivation Decile\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 20. NEWS2\n",
    "if \"NEWS2\" in df_my.columns:\n",
    "    df_my[\"NEWS2_missing\"] = df_my[\"NEWS2\"].isna().astype(\"int64\")\n",
    "    df_my[\"NEWS2\"] = df_my[\"NEWS2\"].replace([\"NA\", \"NaN\", \"\", 0], np.nan)\n",
    "    df_my[\"NEWS2\"] = df_my[\"NEWS2\"].fillna(-1).astype(\"int64\")\n",
    "\n",
    "\n",
    "if target_col in df_my.columns and target_col not in last_20_cols:\n",
    "    df_my = df_my.drop(columns=[target_col])\n",
    "\n",
    "df_my.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NHS Clean)",
   "language": "python",
   "name": "nhs_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
