{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f9d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Dataset shape: (41846, 88)\n",
      "Total features: 88\n",
      "\n",
      "\n",
      "CATEGORIZING FEATURES\n",
      "\n",
      "\n",
      "\n",
      "Numerical features: 81\n",
      "  - Continuous: 34\n",
      "  - Binary: 47\n",
      "\n",
      "Target variable: spell_length_of_stay_hours\n",
      "\n",
      "\n",
      "FEATURE GROUPS\n",
      "\n",
      "\n",
      "\n",
      "Demographics: 4 features\n",
      "\n",
      "Admission_Info: 5 features\n",
      "\n",
      "Clinical_Diagnosis: 7 features\n",
      "\n",
      "Comorbidities: 18 features\n",
      "\n",
      "Chronic_Conditions: 4 features\n",
      "\n",
      "Special_Flags: 4 features\n",
      "\n",
      "Emergency_Department: 10 features\n",
      "\n",
      "\n",
      "NUMERICAL FEATURE CORRELATION ANALYSIS\n",
      "\n",
      "\n",
      "\n",
      "Calculating Spearman correlation...\n",
      "Calculating Pearson correlation...\n",
      "Found 8 correlated groups\n",
      "\n",
      "\n",
      "FEATURE SELECTION - FEATURE-ENGINE\n",
      "\n",
      "\n",
      "\n",
      "Method 1: DropCorrelatedFeatures (Spearman, threshold=0.7)\n",
      "Features to drop: 17\n",
      "\n",
      "Method 2: SmartCorrelatedSelection\n",
      "Target not in numerical features, skipping SmartCorrelatedSelection\n",
      "\n",
      "\n",
      "CORRELATION WITH TARGET VARIABLE: spell_length_of_stay_hours\n",
      "\n",
      "\n",
      "\n",
      "Top 10 features correlated with target (Spearman):\n",
      "                                feature  correlation  p_value\n",
      "38  spell_primary_diagnosis_description     0.518817      0.0\n",
      "20      spell_primary_diagnosis_encoded     0.518793      0.0\n",
      "17          spell_dominant_proc_encoded     0.480100      0.0\n",
      "36                         IP_admission     0.478810      0.0\n",
      "66             arrival_mode_description    -0.476583      0.0\n",
      "68            source_of_ref_description    -0.472181      0.0\n",
      "72              ae_unplanned_attendance     0.460446      0.0\n",
      "77           presenting_complaint_count     0.455483      0.0\n",
      "75              season_of_the_admission     0.454618      0.0\n",
      "67                    place_of_incident    -0.450099      0.0\n",
      "\n",
      "\n",
      "GENERATING EXCEL REPORT\n",
      "\n",
      "\n",
      "Excel report saved: feature_selection_report.xlsx\n",
      "\n",
      "\n",
      "GENERATING HEATMAPS\n",
      "\n",
      "\n",
      "\n",
      "Generating heatmap for Demographics...\n",
      "Saved: heatmap_Demographics.png\n",
      "\n",
      "Generating heatmap for Admission_Info...\n",
      "Saved: heatmap_Admission_Info.png\n",
      "\n",
      "Generating heatmap for Clinical_Diagnosis...\n",
      "Saved: heatmap_Clinical_Diagnosis.png\n",
      "\n",
      "Generating heatmap for Comorbidities...\n",
      "Saved: heatmap_Comorbidities.png\n",
      "\n",
      "Generating heatmap for Chronic_Conditions...\n",
      "Saved: heatmap_Chronic_Conditions.png\n",
      "\n",
      "Generating heatmap for Special_Flags...\n",
      "Saved: heatmap_Special_Flags.png\n",
      "\n",
      "Generating heatmap for Emergency_Department...\n",
      "Saved: heatmap_Emergency_Department.png\n",
      "\n",
      "Generating overall high correlation heatmap...\n",
      "   Saved: heatmap_high_correlations.png\n",
      "\n",
      "\n",
      "FEATURE SELECTION RECOMMENDATIONS\n",
      "\n",
      "\n",
      "\n",
      "Total features analyzed: 80\n",
      "Recommended to DROP: 17\n",
      "Recommended to KEEP: 63\n",
      "\n",
      " Complete\n",
      "\n",
      "\n",
      "APPLYING FEATURE DROPPING\n",
      "\n",
      "\n",
      "Original dataset shape: (41846, 88)\n",
      "Reduced dataset shape: (41846, 71)\n",
      "Features removed: 17\n",
      "\n",
      "✓ Reduced dataset saved: data_reduced.csv\n",
      " Dropped features list saved: dropped_features_list.csv\n",
      "\n",
      "\n",
      "FEATURE RETENTION SUMMARY\n",
      "\n",
      "\n",
      "Original features: 88\n",
      "Retained features: 71\n",
      "Retention rate: 80.7%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection\n",
    "import toad\n",
    "\n",
    "# 1. LOAD DATA\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(\"../../data/data.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Total features: {df.shape[1]}\")\n",
    "\n",
    "# 2. FEATURE CATEGORIZATION\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"CATEGORIZING FEATURES\")\n",
    "\n",
    "# Separate features by type\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Further categorize numerical features\n",
    "binary_features = [col for col in numerical_features if df[col].nunique() == 2]\n",
    "continuous_features = [col for col in numerical_features if col not in binary_features]\n",
    "\n",
    "print(f\"\\nNumerical features: {len(numerical_features)}\")\n",
    "print(f\"  - Continuous: {len(continuous_features)}\")\n",
    "print(f\"  - Binary: {len(binary_features)}\")\n",
    "\n",
    "# 3. TARGET VARIABLE\n",
    "\n",
    "TARGET = 'spell_length_of_stay_hours' \n",
    "print(f\"\\nTarget variable: {TARGET}\")\n",
    "\n",
    "# Remove target from feature lists\n",
    "if TARGET in continuous_features:\n",
    "    continuous_features.remove(TARGET)\n",
    "if TARGET in numerical_features:\n",
    "    numerical_features.remove(TARGET)\n",
    "\n",
    "# 4. CORRELATION ANALYSIS FUNCTIONS\n",
    "\n",
    "def calculate_correlation_matrix(data, method='spearman'):\n",
    "    \"\"\"Calculate correlation matrix using following methods\"\"\"\n",
    "    if method == 'spearman':\n",
    "        corr_matrix = data.corr(method='spearman')\n",
    "    elif method == 'pearson':\n",
    "        corr_matrix = data.corr(method='pearson')\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'spearman' or 'pearson'\")\n",
    "    return corr_matrix\n",
    "\n",
    "# 5. FEATURE GROUPING FOR VISUALIZATION\n",
    "\n",
    "feature_groups = {\n",
    "    'Demographics': [\n",
    "        'ethnic_origin_description',\n",
    "        'patient_age_on_admission',\n",
    "        'sex_national_code',\n",
    "        'Deprivation Decile'\n",
    "    ],\n",
    "    'Admission_Info': [\n",
    "        'elective_admission_flag',\n",
    "        'non_elective_admission_flag',\n",
    "        'IP_admission',\n",
    "        'ward_type_admission',\n",
    "        'general_medical_practice_desc'\n",
    "    ],\n",
    "    'Clinical_Diagnosis': [\n",
    "        'spell_primary_diagnosis_encoded',\n",
    "        'spell_secondary_diagnosis_encoded',\n",
    "        'spell_primary_diagnosis_description',\n",
    "        'spell_dominant_proc_encoded',\n",
    "        'spell_dominant_proc_description',\n",
    "        'hrg_group',\n",
    "        'hrg_sub_group_encoded'\n",
    "    ],\n",
    "    'Comorbidities': [col for col in df.columns if 'comorbidity_' in col],\n",
    "    'Chronic_Conditions': [col for col in df.columns if 'chronic_condition_' in col],\n",
    "    'Special_Flags': [\n",
    "        'dementia_diagnosis_flag',\n",
    "        'covid19_diagnosis_flag',\n",
    "        'frailty_score',\n",
    "        'comorbidity_score'\n",
    "    ],\n",
    "    'Emergency_Department': [\n",
    "        'attendancetype',\n",
    "        'arrival_mode_description',\n",
    "        'place_of_incident',\n",
    "        'source_of_ref_description',\n",
    "        'presenting_complaint_encoded',\n",
    "        'acuity_code',\n",
    "        'inj_or_ail',\n",
    "        'NEWS2',\n",
    "        'ae_unplanned_attendance',\n",
    "        'location'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Filter groups to only include columns that exist\n",
    "feature_groups = {\n",
    "    group: [col for col in cols if col in df.columns]\n",
    "    for group, cols in feature_groups.items()\n",
    "}\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"FEATURE GROUPS\")\n",
    "for group, cols in feature_groups.items():\n",
    "    print(f\"\\n{group}: {len(cols)} features\")\n",
    "\n",
    "# 6. CORRELATION ANALYSIS - NUMERICAL FEATURES\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"NUMERICAL FEATURE CORRELATION ANALYSIS\")\n",
    "\n",
    "# Prepare numerical data\n",
    "numerical_data = df[numerical_features].copy()\n",
    "\n",
    "# Calculate correlations using both methods\n",
    "print(\"\\nCalculating Spearman correlation...\")\n",
    "spearman_corr = calculate_correlation_matrix(numerical_data, method='spearman')\n",
    "\n",
    "print(\"Calculating Pearson correlation...\")\n",
    "pearson_corr = calculate_correlation_matrix(numerical_data, method='pearson')\n",
    "\n",
    "# 7. IDENTIFY CORRELATED FEATURE GROUPS\n",
    "\n",
    "def find_correlated_groups(corr_matrix, threshold=0.7):\n",
    "    \"\"\"Identify groups of correlated features\"\"\"\n",
    "    corr_matrix_abs = corr_matrix.abs()\n",
    "    np.fill_diagonal(corr_matrix_abs.values, 0)\n",
    "    \n",
    "    groups = []\n",
    "    processed = set()\n",
    "    \n",
    "    for col in corr_matrix.columns:\n",
    "        if col in processed:\n",
    "            continue\n",
    "        \n",
    "        # Find all features correlated with this one\n",
    "        correlated = corr_matrix_abs[col][corr_matrix_abs[col] > threshold].index.tolist()\n",
    "        \n",
    "        if correlated:\n",
    "            group = [col] + correlated\n",
    "            groups.append({\n",
    "                'features': group,\n",
    "                'size': len(group),\n",
    "                'avg_correlation': corr_matrix_abs.loc[group, group].values[np.triu_indices(len(group), k=1)].mean()\n",
    "            })\n",
    "            processed.update(group)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Find correlated groups using Spearman\n",
    "correlated_groups_spearman = find_correlated_groups(spearman_corr, threshold=0.7)\n",
    "print(f\"Found {len(correlated_groups_spearman)} correlated groups\")\n",
    "\n",
    "# 8. FEATURE SELECTION USING FEATURE-ENGINE\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"FEATURE SELECTION - FEATURE-ENGINE\")\n",
    "\n",
    "# Method 1: DropCorrelatedFeatures\n",
    "print(\"\\nMethod 1: DropCorrelatedFeatures (Spearman, threshold=0.7)\")\n",
    "dcf = DropCorrelatedFeatures(\n",
    "    variables=None,\n",
    "    method='spearman',\n",
    "    threshold=0.7,\n",
    "    missing_values='ignore'\n",
    ")\n",
    "\n",
    "dcf.fit(numerical_data)\n",
    "features_to_drop_dcf = dcf.features_to_drop_\n",
    "print(f\"Features to drop: {len(features_to_drop_dcf)}\")\n",
    "\n",
    "# Method 2: SmartCorrelatedSelection\n",
    "print(\"\\nMethod 2: SmartCorrelatedSelection\")\n",
    "if TARGET in numerical_data.columns:\n",
    "    scs = SmartCorrelatedSelection(\n",
    "        variables=None,\n",
    "        method='spearman',\n",
    "        threshold=0.7,\n",
    "        missing_values='ignore',\n",
    "        selection_method='variance',\n",
    "        estimator=None\n",
    "    )\n",
    "    \n",
    "    scs.fit(numerical_data)\n",
    "    features_to_drop_scs = scs.features_to_drop_\n",
    "    print(f\"Features to drop: {len(features_to_drop_scs)}\")\n",
    "else:\n",
    "    features_to_drop_scs = []\n",
    "    print(\"Target not in numerical features, skipping SmartCorrelatedSelection\")\n",
    "\n",
    "# 9. CORRELATION WITH TARGET\n",
    "\n",
    "if TARGET in df.columns:\n",
    "    print(\"\\n\")\n",
    "    print(f\"CORRELATION WITH TARGET VARIABLE: {TARGET}\")\n",
    "    \n",
    "    target_corr_spearman = []\n",
    "    target_corr_pearson = []\n",
    "    \n",
    "    for col in numerical_features:\n",
    "        if col != TARGET:\n",
    "            try:\n",
    "                # Spearman\n",
    "                s_corr, s_pval = spearmanr(df[col].fillna(0), df[TARGET].fillna(0))\n",
    "                target_corr_spearman.append({\n",
    "                    'feature': col,\n",
    "                    'correlation': s_corr,\n",
    "                    'p_value': s_pval\n",
    "                })\n",
    "                \n",
    "                # Pearson\n",
    "                p_corr, p_pval = pearsonr(df[col].fillna(0), df[TARGET].fillna(0))\n",
    "                target_corr_pearson.append({\n",
    "                    'feature': col,\n",
    "                    'correlation': p_corr,\n",
    "                    'p_value': p_pval\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    target_corr_spearman_df = pd.DataFrame(target_corr_spearman).sort_values('correlation', \n",
    "                                                                              key=abs, \n",
    "                                                                              ascending=False)\n",
    "    target_corr_pearson_df = pd.DataFrame(target_corr_pearson).sort_values('correlation', \n",
    "                                                                            key=abs, \n",
    "                                                                            ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 features correlated with target (Spearman):\")\n",
    "    print(target_corr_spearman_df.head(10))\n",
    "\n",
    "# 10. CREATE EXCEL REPORT\n",
    "print(\"\\n\")\n",
    "print(\"GENERATING EXCEL REPORT\")\n",
    "\n",
    "with pd.ExcelWriter('./output/feature_selection_report.xlsx', engine='openpyxl') as writer:\n",
    "    \n",
    "    # Sheet 1: Summary\n",
    "    summary_data = {\n",
    "        'Metric': [\n",
    "            'Total Features',\n",
    "            'Numerical Features',\n",
    "            'Binary Features',\n",
    "            'Continuous Features',\n",
    "            'Features to Drop (DropCorrelatedFeatures)',\n",
    "            'Features to Drop (SmartCorrelatedSelection)',\n",
    "            'Correlated Groups Found',\n",
    "            'Target Variable'\n",
    "        ],\n",
    "        'Value': [\n",
    "            df.shape[1],\n",
    "            len(numerical_features),\n",
    "            len(binary_features),\n",
    "            len(continuous_features),\n",
    "            len(features_to_drop_dcf),\n",
    "            len(features_to_drop_scs),\n",
    "            len(correlated_groups_spearman),\n",
    "            TARGET\n",
    "        ]\n",
    "    }\n",
    "    pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n",
    "    \n",
    "    # Sheet 2: Features to Drop/Keep (DropCorrelatedFeatures)\n",
    "    drop_keep_dcf = pd.DataFrame({\n",
    "        'Feature': numerical_features,\n",
    "        'Decision': ['DROP' if f in features_to_drop_dcf else 'KEEP' for f in numerical_features],\n",
    "        'Method': 'DropCorrelatedFeatures'\n",
    "    })\n",
    "    drop_keep_dcf.to_excel(writer, sheet_name='Drop_Keep_DCF', index=False)\n",
    "    \n",
    "    # Sheet 3: Features to Drop/Keep (SmartCorrelatedSelection)\n",
    "    if features_to_drop_scs:\n",
    "        drop_keep_scs = pd.DataFrame({\n",
    "            'Feature': numerical_features,\n",
    "            'Decision': ['DROP' if f in features_to_drop_scs else 'KEEP' for f in numerical_features],\n",
    "            'Method': 'SmartCorrelatedSelection'\n",
    "        })\n",
    "        drop_keep_scs.to_excel(writer, sheet_name='Drop_Keep_SCS', index=False)\n",
    "    \n",
    "    # Sheet 4: Correlated Groups\n",
    "    groups_data = []\n",
    "    for i, group in enumerate(correlated_groups_spearman, 1):\n",
    "        for feature in group['features']:\n",
    "            groups_data.append({\n",
    "                'Group_ID': i,\n",
    "                'Feature': feature,\n",
    "                'Group_Size': group['size'],\n",
    "                'Avg_Correlation': round(group['avg_correlation'], 4),\n",
    "                'Method': 'Spearman'\n",
    "            })\n",
    "    \n",
    "    if groups_data:\n",
    "        pd.DataFrame(groups_data).to_excel(writer, sheet_name='Correlated_Groups', index=False)\n",
    "    \n",
    "    # Sheet 5: Correlation with Target (Spearman)\n",
    "    if TARGET in df.columns and len(target_corr_spearman_df) > 0:\n",
    "        target_corr_spearman_df.to_excel(writer, sheet_name='Target_Corr_Spearman', index=False)\n",
    "    \n",
    "    # Sheet 6: Correlation with Target (Pearson)\n",
    "    if TARGET in df.columns and len(target_corr_pearson_df) > 0:\n",
    "        target_corr_pearson_df.to_excel(writer, sheet_name='Target_Corr_Pearson', index=False)\n",
    "    \n",
    "    # Sheet 7: Full Correlation Matrix (Spearman)\n",
    "    spearman_corr.to_excel(writer, sheet_name='Full_Corr_Spearman')\n",
    "    \n",
    "    # Sheet 8: Full Correlation Matrix (Pearson)\n",
    "    pearson_corr.to_excel(writer, sheet_name='Full_Corr_Pearson')\n",
    "    \n",
    "    # Sheet 9: Methods Used\n",
    "    methods_info = pd.DataFrame({\n",
    "        'Analysis_Type': [\n",
    "            'Numerical-Numerical Correlation',\n",
    "            'Numerical-Numerical Correlation',\n",
    "            'Feature Selection Method 1',\n",
    "            'Feature Selection Method 2',\n",
    "            'Target Correlation Analysis',\n",
    "        ],\n",
    "        'Method': [\n",
    "            'Spearman',\n",
    "            'Pearson',\n",
    "            'DropCorrelatedFeatures (Spearman)',\n",
    "            'SmartCorrelatedSelection (Spearman)',\n",
    "            'Spearman & Pearson',\n",
    "        ],\n",
    "        'Threshold': [\n",
    "            '0.7',\n",
    "            '0.7',\n",
    "            '0.7',\n",
    "            '0.7',\n",
    "            'N/A',\n",
    "        ],\n",
    "        'Description': [\n",
    "            'Non-parametric correlation for continuous and ordinal variables',\n",
    "            'Parametric correlation for continuous variables (assumes normality)',\n",
    "            'Drops one feature from each correlated pair',\n",
    "            'Smart selection based on variance and target correlation',\n",
    "            'Correlation of features with target variable',\n",
    "        ]\n",
    "    })\n",
    "    methods_info.to_excel(writer, sheet_name='Methods_Used', index=False)\n",
    "\n",
    "print(\"Excel report saved: feature_selection_report.xlsx\")\n",
    "\n",
    "# 11. VISUALIZATION - HEATMAPS BY GROUP\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"GENERATING HEATMAPS\")\n",
    "\n",
    "def plot_correlation_heatmap(corr_matrix, title, figsize=(12, 10)):\n",
    "    \"\"\"Plot correlation heatmap\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm', \n",
    "                center=0, vmin=-1, vmax=1, square=True, \n",
    "                linewidths=0.5, cbar_kws={\"shrink\": 0.7})\n",
    "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "# Plot heatmaps for each feature group\n",
    "for group_name, group_features in feature_groups.items():\n",
    "    # Get numerical features in this group\n",
    "    group_num_features = [f for f in group_features if f in numerical_features]\n",
    "    \n",
    "    if len(group_num_features) > 1:\n",
    "        print(f\"\\nGenerating heatmap for {group_name}...\")\n",
    "        \n",
    "        # Get correlation submatrix\n",
    "        group_corr = spearman_corr.loc[group_num_features, group_num_features]\n",
    "        \n",
    "        # Plot\n",
    "        fig = plot_correlation_heatmap(\n",
    "            group_corr, \n",
    "            f'Correlation Heatmap: {group_name} (Spearman)',\n",
    "            figsize=(min(len(group_num_features)*0.8, 20), min(len(group_num_features)*0.7, 18))\n",
    "        )\n",
    "        plt.savefig(f'./heatmaps/heatmap_{group_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Saved: heatmap_{group_name}.png\")\n",
    "\n",
    "# Overall heatmap for high correlation pairs\n",
    "print(\"\\nGenerating overall high correlation heatmap...\")\n",
    "high_corr_mask = (spearman_corr.abs() > 0.7) & (spearman_corr.abs() < 1.0)\n",
    "high_corr_features = high_corr_mask.any(axis=1)\n",
    "high_corr_subset = spearman_corr.loc[high_corr_features, high_corr_features]\n",
    "\n",
    "if len(high_corr_subset) > 0:\n",
    "    fig = plot_correlation_heatmap(\n",
    "        high_corr_subset,\n",
    "        'High Correlation Features (|r| > 0.7, Spearman)',\n",
    "        figsize=(16, 14)\n",
    "    )\n",
    "    plt.savefig('./heatmaps/heatmap_high_correlations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"   Saved: heatmap_high_correlations.png\")\n",
    "\n",
    "# 12. FINAL RECOMMENDATIONS\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"FEATURE SELECTION RECOMMENDATIONS\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Combine recommendations\n",
    "features_to_drop_final = list(set(features_to_drop_dcf) | set(features_to_drop_scs))\n",
    "features_to_keep = [f for f in numerical_features if f not in features_to_drop_final]\n",
    "\n",
    "print(f\"\\nTotal features analyzed: {len(numerical_features)}\")\n",
    "print(f\"Recommended to DROP: {len(features_to_drop_final)}\")\n",
    "print(f\"Recommended to KEEP: {len(features_to_keep)}\")\n",
    "\n",
    "print(\"\\n Complete\")\n",
    "\n",
    "# Save final recommendations to CSV\n",
    "final_recommendations = pd.DataFrame({\n",
    "    'Feature': numerical_features,\n",
    "    'Recommendation': ['DROP' if f in features_to_drop_final else 'KEEP' \n",
    "                       for f in numerical_features],\n",
    "    'Dropped_by_DCF': [f in features_to_drop_dcf for f in numerical_features],\n",
    "    'Dropped_by_SCS': [f in features_to_drop_scs for f in numerical_features]\n",
    "})\n",
    "\n",
    "final_recommendations.to_csv('./output/feature_selection_recommendations.csv', index=False)\n",
    "\n",
    "# 13. APPLY FEATURE DROPPING\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"APPLYING FEATURE DROPPING\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Create a new DataFrame with dropped features\n",
    "df_reduced = df.copy()\n",
    "\n",
    "# Drop the recommended features\n",
    "df_reduced = df_reduced.drop(columns=features_to_drop_final)\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Reduced dataset shape: {df_reduced.shape}\")\n",
    "print(f\"Features removed: {df.shape[1] - df_reduced.shape[1]}\")\n",
    "\n",
    "# Save the reduced dataset\n",
    "df_reduced.to_csv('../../data/data_reduced.csv', index=False)\n",
    "print(\"\\n✓ Reduced dataset saved: data_reduced.csv\")\n",
    "\n",
    "# Optional: Save list of dropped features for reference\n",
    "dropped_features_df = pd.DataFrame({\n",
    "    'Dropped_Feature': features_to_drop_final,\n",
    "    'Reason': ['High correlation with other features'] * len(features_to_drop_final)\n",
    "})\n",
    "dropped_features_df.to_csv('./output/dropped_features_list.csv', index=False)\n",
    "print(\" Dropped features list saved: dropped_features_list.csv\")\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\n\")\n",
    "print(\"FEATURE RETENTION SUMMARY\")\n",
    "print(\"\\n\")\n",
    "print(f\"Original features: {df.shape[1]}\")\n",
    "print(f\"Retained features: {df_reduced.shape[1]}\")\n",
    "print(f\"Retention rate: {(df_reduced.shape[1] / df.shape[1]) * 100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
