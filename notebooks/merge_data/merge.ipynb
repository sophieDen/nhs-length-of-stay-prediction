{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af8d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: merge_Jin_col_1_20.csv\n",
      "Found: merge_Issa_col_21_40.csv\n",
      "Found: merge_Ali_col_40_60.csv\n",
      "Found: merge_Xiaomei_col_60_80.csv\n",
      "Found: merge_Sophie_col_80_100.csv\n",
      "\n",
      "\n",
      " UNWANTED COLUMN CHECK\n",
      "\n",
      "\n",
      "Dropped columns:\n",
      "   - readmission_flag_28_days\n",
      "   - emergency_readmission_non_pbr_30\n",
      "   - readmission_flag_28_days_emergancy\n",
      "   - discharge_created_datetime\n",
      "   - discharge_letter_status\n",
      "   - IP_discharge\n",
      "   - ward_type_discharge\n",
      "\n",
      "data.csv created with unwanted columns removed\n",
      "\n",
      "\n",
      " COLUMN VALIDATION REPORT\n",
      "\n",
      "\n",
      "No missing columns — all required columns are present.\n",
      "\n",
      "\n",
      "Extra columns present (not in the required list):\n",
      "   - site_national_code_RRF01\n",
      "   - site_national_code_RRF02\n",
      "   - site_national_code_RRF53\n",
      "   - site_national_code_RRF70\n",
      "   - Admission_Hour\n",
      "   - Admission_Day\n",
      "   - Admission_Month\n",
      "   - specialty_spec_code_Children_Spec\n",
      "   - specialty_spec_code_Medical_Spec\n",
      "   - specialty_spec_code_Other\n",
      "   - specialty_spec_code_Surgical_Spec\n",
      "   - ward_code_admission_1\n",
      "   - ward_code_admission_2\n",
      "   - ward_code_admission_3\n",
      "   - ward_code_admission_4\n",
      "   - spell_dominant_proc_count\n",
      "   - spell_dominant_proc_is_rare\n",
      "   - spell_primary_diagnosis_count\n",
      "   - spell_primary_diagnosis_is_rare\n",
      "   - spell_secondary_diagnosis_count\n",
      "   - spell_secondary_diagnosis_is_rare\n",
      "   - spec_div_Medicine\n",
      "   - spec_div_Specialist Services\n",
      "   - spec_div_Surgery\n",
      "   - spec_direc_Medicine\n",
      "   - spec_direc_Specialist Services\n",
      "   - spec_direc_Surgery\n",
      "   - spec_direc_Womens Health\n",
      "   - hrg_sub_group_count\n",
      "   - hrg_sub_group_is_rare\n",
      "   - readmission_flag_30_days\n",
      "   - readmission_flag_30_days_emergancy\n",
      "   - season_of_the_admission\n",
      "   - presenting_complaint_count\n",
      "   - presenting_complaint_is_rare\n",
      "   - NEWS2_missing\n",
      "\n",
      "\n",
      "No NaN values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder = \"../../data/processed/\"\n",
    "\n",
    "expected_files = [\n",
    "    \"merge_Jin_col_1_20.csv\",\n",
    "    \"merge_Issa_col_21_40.csv\",\n",
    "    \"merge_Ali_col_40_60.csv\",\n",
    "    \"merge_Xiaomei_col_60_80.csv\",\n",
    "    \"merge_Sophie_col_80_100.csv\"\n",
    "]\n",
    "\n",
    "# Columns to remove from the final dataset\n",
    "columns_to_remove = [\n",
    "    \"ward_code_discharge\",\n",
    "    \"duration_elective_wait\",\n",
    "    \"readmission_flag_28_days\",\n",
    "    \"inpatient_death_flag\",\n",
    "    \"spell_days_elective\",\n",
    "    \"spell_days_non_elective\",\n",
    "    \"emergency_readmission_non_pbr_30\",\n",
    "    \"readmission_flag_28_days_emergancy\",\n",
    "    \"discharge_created_datetime\",\n",
    "    \"discharge_letter_status\",\n",
    "    \"IP_discharge\",\n",
    "    \"ward_type_discharge\",\n",
    "    \"site_description\",\n",
    "    \"site_local_code\",\n",
    "    \"Admission_Date\",\n",
    "    \"admission_date_dt\",\n",
    "    \"discharge_date_dt\",\n",
    "    \"specialty_local_code\",\n",
    "    \"specialty_spec_desc\",\n",
    "    \"ward_name_discharge\",\n",
    "    \"ward_name_admission\",\n",
    "    \"date_of_birth_dt\",\n",
    "    \"date_of_death_dt\",\n",
    "    \"patient_age_on_discharge\",\n",
    "    \"discharge_delay_reason_national_code\",\n",
    "    \"discharge_delay_reason_description\",\n",
    "    \"delayed_discharges_flag\",\n",
    "    \"delayed_discharges_no_of_days\",\n",
    "    \"social_worker_date_time_referred\",\n",
    "    \"discharge_letter_sent\",\n",
    "    \"discharge_letter_sent_in_24hrs\",\n",
    "    \"medically_optimised\",\n",
    "    \"covid19_diagnosis_description\",\n",
    "    \"chronic_condition_diabetes_flag\",\n",
    "    \"comorbidity_pulmonary_disease_flag\",\n",
    "    \"chronic_condition_hypertension_flag\",\n",
    "    \"Arrival_Date\",\n",
    "    \"arrival_date_time\",\n",
    "    \"initial_assessment_date_time\",\n",
    "    \"attend_dis_description\",\n",
    "    \"sex_description.y\",\n",
    "    \"ID\",\n",
    "    \"spell_episode_los\"\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in expected_files:\n",
    "    path = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Found: {filename}\")\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Remove index column in case someone's saved with index\n",
    "        df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "        dfs.append(df)\n",
    "    else:\n",
    "        print(f\"Missing: {filename}\")\n",
    "\n",
    "if dfs:\n",
    "    df_merged = pd.concat(dfs, axis=1)\n",
    "\n",
    "    # Drop unwanted columns \n",
    "    print(\"columns check\")\n",
    "    \n",
    "    cols_found = []\n",
    "    cols_not_found = []\n",
    "\n",
    "    for col in columns_to_remove:\n",
    "        if col in df_merged.columns:\n",
    "            cols_found.append(col)\n",
    "        else:\n",
    "            cols_not_found.append(col)\n",
    "\n",
    "    # Drop only those that exist\n",
    "    if cols_found:\n",
    "        df_merged = df_merged.drop(columns=cols_found, errors=\"ignore\")\n",
    "        print(\"Dropped columns:\")\n",
    "        for c in cols_found:\n",
    "            print(\"   -\", c)\n",
    "    else:\n",
    "        print(\"No unwanted columns were present.\")\n",
    "\n",
    "    # Write without index\n",
    "    df_merged.to_csv(\"../../data/data.csv\", index=False)\n",
    "\n",
    "    print(\"\\ndata.csv created \")\n",
    "else:\n",
    "    print(\"No files available to merge\")\n",
    "\n",
    "# Validation of final dataset\n",
    "\n",
    "if dfs:\n",
    "    required_columns = [\n",
    "        # \"site_national_code\",  one hot encoded \n",
    "        # \"specialty_spec_code\", one hot encoded \n",
    "        # \"ward_code_admission\", one hot encoded \n",
    "        \"ethnic_origin_description\",\n",
    "        \"patient_age_on_admission\",\n",
    "        \"spell_dominant_proc_encoded\",\n",
    "        \"spell_primary_diagnosis_encoded\",\n",
    "        \"spell_secondary_diagnosis_encoded\",\n",
    "        \"spell_length_of_stay_hours\",\n",
    "        #\"specialty_division\", one hot encoded so not present\n",
    "        #\"specialty_directorate\",\n",
    "        \"hrg_group\",\n",
    "        \"hrg_sub_group_encoded\",\n",
    "        \"sex_national_code\",\n",
    "        \"elective_admission_flag\",\n",
    "        \"non_elective_admission_flag\",\n",
    "        \"general_medical_practice_desc\",\n",
    "        \"IP_admission\",\n",
    "        \"ward_type_admission\",\n",
    "        \"spell_primary_diagnosis_description\",\n",
    "        \"spell_dominant_proc_description\",\n",
    "        \"dementia_diagnosis_flag\",\n",
    "        \"covid19_diagnosis_flag\",\n",
    "        \"comorbidity_score\",\n",
    "        \"comorbidity_acute_myocardial_infarction_flag\",\n",
    "        \"comorbidity_cancer_flag\",\n",
    "        \"comorbidity_cerebral_vascular_accident_flag\",\n",
    "        \"comorbidity_dementia_flag\",\n",
    "        \"comorbidity_congestive_heart_failure_flag\",\n",
    "        \"comorbidity_conncective_tissue_disorder_flag\",\n",
    "        \"comorbidity_diabetes_complications_flag\",\n",
    "        \"comorbidity_diabetes_flag\",\n",
    "        \"comorbidity_hiv_flag\",\n",
    "        \"comorbidity_liver_disease_flag\",\n",
    "        \"comorbidity_metastatic_cancer_flag\",\n",
    "        \"comorbidity_paraplegia_flag\",\n",
    "        \"comorbidity_peptic_ulcer_flag\",\n",
    "        \"comorbidity_peripheral_vascular_disease_flag\",\n",
    "        \"comorbidity_renal_disease_flag\",\n",
    "        \"comorbidity_severe_liver_disease_flag\",\n",
    "        \"chronic_condition_asthma_flag\",\n",
    "        \"chronic_condition_cardiovascular_disease_flag\",\n",
    "        \"chronic_condition_obesity_flag\",\n",
    "        \"chronic_condition_respiratory_flag\",\n",
    "        \"frailty_score\",\n",
    "        \"attendancetype\",\n",
    "        \"arrival_mode_description\",\n",
    "        \"place_of_incident\",\n",
    "        \"source_of_ref_description\",\n",
    "        \"presenting_complaint_encoded\",\n",
    "        \"acuity_code\",\n",
    "        \"inj_or_ail\",\n",
    "        \"NEWS2\",\n",
    "        \"ae_unplanned_attendance\",\n",
    "        \"location\",\n",
    "        \"Deprivation Decile\"\n",
    "    ]\n",
    "\n",
    "    missing_columns = [col for col in required_columns if col not in df_merged.columns]\n",
    "\n",
    "    # Columns that are unexpected to be there\n",
    "    extra_columns = [col for col in df_merged.columns if col not in required_columns]\n",
    "\n",
    "    # NaN check\n",
    "    nan_counts = df_merged.isna().sum()\n",
    "    total_nans = nan_counts.sum()\n",
    "\n",
    "    # Output report\n",
    "    print(\"Column validation report\")\n",
    "    \n",
    "    # Missing columns\n",
    "    if missing_columns:\n",
    "        print(\"Missing columns:\")\n",
    "        for col in missing_columns:\n",
    "            print(\"   -\", col)\n",
    "    else:\n",
    "        print(\"No missing columns, all required columns are present\")\n",
    "\n",
    "    # Extra columns check\n",
    "    if extra_columns:\n",
    "        print(\"Extra columns present (not in the required list):\")\n",
    "        for col in extra_columns:\n",
    "            print(\"   -\", col)\n",
    "    else:\n",
    "        print(\"No unexpected columns — dataset matches schema exactly.\")\n",
    "\n",
    "    # NaN check\n",
    "    if total_nans > 0:\n",
    "        print(f\"Dataset contains {total_nans:,} NaN values.\\n\")\n",
    "        print(\"Columns with NaNs:\")\n",
    "        for col, count in nan_counts[nan_counts > 0].items():\n",
    "            print(f\"   {col}: {count:,} NaNs\")\n",
    "    else:\n",
    "        print(\"No NaN values in the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
